{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 671 images belonging to 2 classes.\n",
      "Found 74 images belonging to 2 classes.\n",
      "Found 187 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "20/20 [==============================] - 80s 4s/step - loss: 1.0646 - accuracy: 0.8013 - val_loss: 1.0669 - val_accuracy: 0.7500\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.8207 - accuracy: 0.9092 - val_loss: 1.5879 - val_accuracy: 0.8333\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 54s 3s/step - loss: 0.7554 - accuracy: 0.9437 - val_loss: 1.2843 - val_accuracy: 0.8333\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 54s 3s/step - loss: 0.7355 - accuracy: 0.9500 - val_loss: 0.7025 - val_accuracy: 0.9531\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 56s 3s/step - loss: 0.7373 - accuracy: 0.9373 - val_loss: 0.6026 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.7015 - accuracy: 0.9624 - val_loss: 0.5896 - val_accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6760 - accuracy: 0.9672 - val_loss: 0.5886 - val_accuracy: 0.9531\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.6753 - accuracy: 0.9624 - val_loss: 1.3071 - val_accuracy: 0.9048\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 56s 3s/step - loss: 0.6963 - accuracy: 0.9499 - val_loss: 0.9311 - val_accuracy: 0.8333\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6341 - accuracy: 0.9734 - val_loss: 0.5738 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6209 - accuracy: 0.9750 - val_loss: 0.6201 - val_accuracy: 0.9524\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6168 - accuracy: 0.9718 - val_loss: 0.7303 - val_accuracy: 0.9048\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.6581 - accuracy: 0.9719 - val_loss: 0.6351 - val_accuracy: 0.9844\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6021 - accuracy: 0.9797 - val_loss: 0.5504 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.5947 - accuracy: 0.9812 - val_loss: 0.5563 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.5930 - accuracy: 0.9750 - val_loss: 0.5489 - val_accuracy: 0.9375\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.6238 - accuracy: 0.9718 - val_loss: 0.5398 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.6024 - accuracy: 0.9765 - val_loss: 0.5620 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.5705 - accuracy: 0.9859 - val_loss: 0.5523 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 63s 3s/step - loss: 0.5791 - accuracy: 0.9781 - val_loss: 0.5853 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.5653 - accuracy: 0.9890 - val_loss: 0.5506 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.5546 - accuracy: 0.9922 - val_loss: 0.5720 - val_accuracy: 0.9844\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.5703 - accuracy: 0.9828 - val_loss: 0.5236 - val_accuracy: 0.9762\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 55s 3s/step - loss: 0.5701 - accuracy: 0.9844 - val_loss: 0.5922 - val_accuracy: 0.9524\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.5567 - accuracy: 0.9875 - val_loss: 0.6167 - val_accuracy: 0.9688\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Glaucoma       0.98      1.00      0.99        83\n",
      "Non Glaucoma       1.00      0.98      0.99       104\n",
      "\n",
      "    accuracy                           0.99       187\n",
      "   macro avg       0.99      0.99      0.99       187\n",
      "weighted avg       0.99      0.99      0.99       187\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-537609353704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss and Accuracy on Dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from cnn.resnet import ResNet\n",
    "from cnn import config\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "'''\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "\thelp=\"path to output loss/accuracy plot\")\n",
    "args = vars(ap.parse_args())\n",
    "'''\n",
    "num_epochs = 25\n",
    "init_lr= 1e-1\n",
    "bs = 32\n",
    " \n",
    "\n",
    "\n",
    "def poly_decay(epoch):\n",
    "\n",
    "\tmaxEpochs = num_epochs\n",
    "\tbaseLR = init_lr\n",
    "\tpower = 0.5 \n",
    " \n",
    "\t\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    " \n",
    "\n",
    "\treturn alpha\n",
    "\n",
    "\n",
    "totalTrain = len(list(paths.list_images(config.train_path)))\n",
    "totalVal = len(list(paths.list_images(config.val_path)))\n",
    "totalTest = len(list(paths.list_images(config.test_path)))\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.train_path,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=bs)\n",
    " \n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.val_path,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=bs)\n",
    " \n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.test_path,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=bs)\n",
    "\n",
    "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
    "\t(64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=init_lr, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // bs,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // bs,\n",
    "\tepochs=num_epochs,\n",
    "\tcallbacks=callbacks)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // bs) + 1)\n",
    " \n",
    "\n",
    "predIdxs = np.argmax(predIdxs, axis=1) \n",
    " \n",
    "\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "N = num_epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = H.history['accuracy']\n",
    "val_accuracy = H.history['val_accuracy']\n",
    "loss = H.history['loss']\n",
    "\n",
    "val_loss = H.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, '-', label='Training Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('F:\\plou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_accuracy, '-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.savefig('F:\\plow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, '-', label = 'Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.savefig('F:\\plowe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_loss, '-', label = 'Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig('F:\\plowie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x0000024C6DE9A7C8>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  if sys.path[0] == '':\n",
      "d:\\anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x0000024C6DE9ACC8>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  if sys.path[0] == '':\n",
      "d:\\anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x0000024C6DFEA488>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  if sys.path[0] == '':\n",
      "d:\\anacona3\\envs\\tf_gpuu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Legend does not support [<matplotlib.lines.Line2D object at 0x0000024C6E01E6C8>] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "accuracy = H.history['accuracy']\n",
    "val_accuracy = H.history['val_accuracy']\n",
    "loss = H.history['loss']\n",
    "val_loss = H.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "line1=plt.plot(epochs, accuracy,'-b',label='line1')\n",
    "plt.legend('label1')\n",
    "line2=plt.plot(epochs, val_accuracy,'-g',label='line2')\n",
    "line3=plt.plot(epochs,loss,'-c',label='line3')\n",
    "line4=plt.plot(epochs,val_loss,'-k',label='line4')\n",
    "\n",
    "plt.legend((line1, line2, line3,line4), ('label1', 'label2', 'label3','label4'))\n",
    "plt.savefig('D:plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = H.history['accuracy']\n",
    "val_accuracy = H.history['val_accuracy']\n",
    "loss = H.history['loss']\n",
    "val_loss = H.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.clf()\n",
    "plt.plot(epochs, accuracy,'-b',label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy,'-g',label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(\"F:plowwwww\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(epochs,loss,'-c',label='Training Loss')\n",
    "plt.plot(epochs,val_loss,'-k',label='Validation Loss')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"D:plow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
